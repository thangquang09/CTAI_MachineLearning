{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652b4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thangquang09/CODE/CTAI_MachineLearning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_logistic import prepare_data_for_model, read_texts_from_dir, train_and_evaluate, compute_rule_based_features\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8b0089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Number of directories: 95\n",
      "Number of directories: 1068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((190, 2), (190,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train\"\n",
    "test_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/test\"\n",
    "gt_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    "print(\"Loading data...\")\n",
    "df_train = read_texts_from_dir(train_path)\n",
    "df_test = read_texts_from_dir(test_path)\n",
    "df_train_gt = pd.read_csv(gt_path)\n",
    "y_train = df_train_gt[\"real_text_id\"].values\n",
    "\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "\n",
    "# Prepare the training dataframe\n",
    "df_train['label'] = y_train - 1\n",
    "\n",
    "# SWAP DATA\n",
    "df_swap = df_train.copy()\n",
    "df_swap['file_1'], df_swap['file_2'] = df_swap['file_2'], df_swap['file_1']\n",
    "df_swap['label'] = 1 - df_swap['label']\n",
    "# CONCAT AUGMENTED DATA TO REAL DATA\n",
    "df_train = pd.concat((df_train, df_swap), axis=0).reset_index(drop=True)\n",
    "\n",
    "# Update y_train to match the new df_train\n",
    "y_train = df_train['label'].values + 1\n",
    "df_train.drop(columns=['label'], inplace=True)\n",
    "\n",
    "df_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52599b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A key focus of modern cosmology is to understa...</td>\n",
       "      <td>A main focus of modern cosmology is to underst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>APEX, as its name suggests, serves as a guide ...</td>\n",
       "      <td>APEX, as its name suggests, serves as a guide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>The observations of the Pluto-Charon binary an...</td>\n",
       "      <td>The observations of the Pluto-Charon system an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file_1  \\\n",
       "185  A key focus of modern cosmology is to understa...   \n",
       "186  APEX, as its name suggests, serves as a guide ...   \n",
       "187  FORS1 and FORS2 are early instruments of the V...   \n",
       "188  The observations of the Pluto-Charon binary an...   \n",
       "189  The new detector system was first tested on 30...   \n",
       "\n",
       "                                                file_2  \n",
       "185  A main focus of modern cosmology is to underst...  \n",
       "186  APEX, as its name suggests, serves as a guide ...  \n",
       "187  FORS1 and FORS2 are early instruments of the V...  \n",
       "188  The observations of the Pluto-Charon system an...  \n",
       "189  The new detector system was first tested on 30...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84f1dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCountsResult(values=array([1, 2]), counts=array([46, 49]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique_counts(df_train_gt[\"real_text_id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e442b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCountsResult(values=array([1, 2]), counts=array([95, 95]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35641fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n",
      "Step 1: Extracting top importance features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting top features: 100%|██████████| 190/190 [00:01<00:00, 100.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 190/190 [00:01<00:00, 164.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 3/3 [00:13<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 3/3 [00:10<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Extracting pairwise features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pairwise features: 100%|██████████| 190/190 [00:00<00:00, 387.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Combining features...\n",
      "Final feature matrix shape: (190, 1654)\n",
      "Top features: 25, Rule: 78, Stat: 6, Embedding: 1538, Pairwise: 7\n",
      "Feature matrix shape: (190, 1654)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'intfloat/multilingual-e5-small'\n",
    "\n",
    "print(\"Preparing training data...\")\n",
    "X_train, embedding_extractor = prepare_data_for_model(\n",
    "    df_train, \n",
    "    fit_embedding=True, \n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "print(f\"Feature matrix shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443f8810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'border_count': 32, 'depth': 6, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
      "Best cross-validation score: 0.9156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the parameter grid, including the current parameters\n",
    "param_grid = {\n",
    "    'iterations': [500],  # Current value\n",
    "    'learning_rate': [0.1],  # Current value\n",
    "    'depth': [6],  # Current value\n",
    "    'l2_leaf_reg': [1, 3, 5],  # Example additional parameter\n",
    "    'border_count': [32, 64]  # Example additional parameter\n",
    "}\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=catboost_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# best score\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best cross-validation score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a0129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracting top importance features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting top features: 100%|██████████| 1068/1068 [00:03<00:00, 324.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 1068/1068 [00:05<00:00, 204.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 17/17 [01:08<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 17/17 [01:12<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Extracting pairwise features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pairwise features: 100%|██████████| 1068/1068 [00:02<00:00, 428.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Combining features...\n",
      "Final feature matrix shape: (1068, 1654)\n",
      "Top features: 25, Rule: 78, Stat: 6, Embedding: 1538, Pairwise: 7\n"
     ]
    }
   ],
   "source": [
    "X_test, _ = prepare_data_for_model(\n",
    "        df_test, \n",
    "        embedding_extractor=embedding_extractor, \n",
    "        fit_embedding=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08ff24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test ...\n",
      "✅ Submission saved to /home/thangquang09/CODE/CTAI_MachineLearning/notebooks/submission_e5_catboost_improved_augmented.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(\"Predicting on test ...\")\n",
    "test_pred = best_model.predict(X_test)\n",
    "\n",
    "# --- Build submission -------------------------------------------------\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test.index,\n",
    "    \"real_text_id\": test_pred.astype(int)\n",
    "}).sort_values(\"id\")\n",
    "\n",
    "save_path = Path(\"submission_e5_catboost_improved_augmented.csv\")\n",
    "submission.to_csv(save_path, index=False)\n",
    "print(f\"✅ Submission saved to {save_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
