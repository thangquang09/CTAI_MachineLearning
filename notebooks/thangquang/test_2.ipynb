{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cee1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_logistic import prepare_data_for_model, read_texts_from_dir, train_and_evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718fd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train\"\n",
    "test_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/test\"\n",
    "gt_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aec8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Number of directories: 95\n",
      "Number of directories: 1068\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "df_train = read_texts_from_dir(train_path)\n",
    "df_test = read_texts_from_dir(test_path)\n",
    "df_train_gt = pd.read_csv(gt_path)\n",
    "y_train = df_train_gt[\"real_text_id\"].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50bf953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "      <th>real_text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_1  \\\n",
       "0  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1  China\\nThe goal of this project involves achie...   \n",
       "2  Scientists can learn about how galaxies form a...   \n",
       "3  China\\nThe study suggests that multiple star s...   \n",
       "4  Dinosaur Rex was excited about his new toy set...   \n",
       "\n",
       "                                              file_2  real_text_id  \n",
       "0  The China relay network has released a signifi...             1  \n",
       "1  The project aims to achieve an accuracy level ...             2  \n",
       "2  Dinosaur eggshells offer clues about what dino...             1  \n",
       "3  The importance for understanding how stars evo...             2  \n",
       "4  Analyzing how fast stars rotate within a galax...             2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_train = pd.concat([df_train, df_train_gt[\"real_text_id\"]], axis=1)\n",
    "full_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0448918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chọn ra random 20 hàng từ full_df_train\n",
    "df_train_sample = full_df_train.sample(n=80, random_state=42)\n",
    "df_train_sample.reset_index(drop=True, inplace=True)\n",
    "df_train_sample.to_json(\"df_train_sample.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "032c7447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n",
      "Step 1: Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning text: 100%|██████████| 95/95 [00:00<00:00, 659.60it/s]\n",
      "Cleaning text: 100%|██████████| 95/95 [00:00<00:00, 1028.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 95/95 [00:00<00:00, 200.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 3/3 [00:08<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Combining all features...\n",
      "Final feature matrix shape: (95, 1580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing training data...\")\n",
    "X_train, embedding_extractor = prepare_data_for_model(\n",
    "    df_train, \n",
    "    fit_embedding=True, \n",
    "    model_name='intfloat/multilingual-e5-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3e001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning text: 100%|██████████| 1068/1068 [00:01<00:00, 966.44it/s]\n",
      "Cleaning text: 100%|██████████| 1068/1068 [00:01<00:00, 857.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 1068/1068 [00:04<00:00, 230.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 34/34 [01:25<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 34/34 [01:29<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Combining all features...\n",
      "Final feature matrix shape: (1068, 1580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test, _ = prepare_data_for_model(\n",
    "        df_test, \n",
    "        embedding_extractor=embedding_extractor, \n",
    "        fit_embedding=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98beeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e14a72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with CatBoost: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "catboost_model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "\n",
    "# Train the model\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_preds_val_catboost = catboost_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc_catboost = accuracy_score(y_val, y_preds_val_catboost)\n",
    "print(f\"Validation accuracy with CatBoost: {acc_catboost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b4f1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test ...\n",
      "✅ Submission saved to /home/thangquang09/CODE/CTAI_MachineLearning/notebooks/submission_e5_catboost.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(\"Predicting on test ...\")\n",
    "test_pred = catboost_model.predict(X_test)\n",
    "\n",
    "# --- Build submission -------------------------------------------------\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test.index,\n",
    "    \"real_text_id\": test_pred.astype(int)\n",
    "}).sort_values(\"id\")\n",
    "\n",
    "save_path = Path(\"submission_e5_catboost.csv\")\n",
    "submission.to_csv(save_path, index=False)\n",
    "print(f\"✅ Submission saved to {save_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1568e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
