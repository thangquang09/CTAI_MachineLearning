{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b92d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_path = '/home/thangquang/CODE/CTAI_MachineLearning/data/ise-dsc01-train_new_preprocessed.json'\n",
    "data = json.load(open(json_path, \"r\", encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c381a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = [ex for ex in data if ex['verdict'] != 'NEI']\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169e11c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phát_biểu tại lễ ký_kết vào ngày 1711 , giám_đốc điều_hành kiêm đồng sáng_lập faba technology - nguyễn thành hưng nhận_định trong bối_cảnh \" bình_thường mới \" như hiện_tại , mô_hình đào_tạo 100 % online của funix là một trong những cách có_thể giải bài_toán khan_hiếm nhân_lực của ngành công_nghệ thông_tin .',\n",
       " 'ông cũng chia_sẻ việc trở_thành đối_tác đào_tạo và tuyển_dụng cùng funix sẽ giúp faba technology đạt mục_tiêu trở_thành_công_ty offshore development chất_lượng nhất trong khu_vực .',\n",
       " 'qua hợp_tác này , faba kỳ_vọng sẽ có ứng_viên chất_lượng cho rất nhiều vị_trí công_việc đang tìm_kiếm như automation tester , uiux designer , web developer , mobile developer ở nhiều cấp_độ ... \" chúng_tôi hoàn_toàn tin_tưởng vào chất_lượng đào_tạo của funix \" - ông nhấn_mạnh .',\n",
       " 'để thu_hút và giữ_chân nhân_tài trong một thị_trường nhân_sự it khốc_liệt , faba không giới_hạn_mức lương , luôn cập_nhật để dải_lương đạt mức cạnh_tranh tốt so với thị_trường .',\n",
       " 'công_ty cũng có chế_độ đãi_ngộ tốt , có lương tháng 13 , 14 , phụ_cấp ... bên cạnh đó , faba thường_xuyên tổ_chức những dự_án đào_tạo kỹ_năng nghề_nghiệp , kỹ_năng mềm , chú_trọng xây_dựng văn_hoá doanh_nghiệp để thúc_đẩy phát_triển đội_ngũ .',\n",
       " 'faba technology thành_lập năm 2016 , chuyên cung_cấp dịch_vụ phát_triển phần_mềm offshore cho nhiều khách_hàng lớn trên toàn_cầu như mỹ , australia , singapore , và châu âu .',\n",
       " 'trong đó có havas - một trong những tập_đoàn quảng_cáo và truyền_thông lớn nhất thế_giới .',\n",
       " 'vân nguyễn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ff2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(ranks, k_list=(1,3,5)):\n",
    "    \"\"\"ranks: vị trí (bắt đầu từ 1) của evidence. None nếu không tìm thấy.\"\"\"\n",
    "    hit1   = 1 if ranks is not None and ranks==1 else 0\n",
    "    mrr    = 1.0 / ranks if ranks is not None else 0.0\n",
    "    recalls = {k: 1 if ranks is not None and ranks<=k else 0 for k in k_list}\n",
    "    return hit1, mrr, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab02780",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_sum = {\n",
    "    'hit1':0,\n",
    "    'mrr':0,\n",
    "    'recall@3':0,\n",
    "    'recall@5':0\n",
    "}\n",
    "N = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb498ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c205df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b32374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for item in tqdm(dataset, desc=\"Evaluating\"):\n",
    "#     claim = item['claim'].strip()\n",
    "#     context_sentences = [s.strip() for s in item['context']]\n",
    "#     gold = item['evidence'].strip()\n",
    "    \n",
    "#     # -------- 4a.  BM25 ranking  ----------\n",
    "#     tokenized_corpus = [sent.split() for sent in context_sentences]\n",
    "#     bm25 = BM25Okapi(tokenized_corpus)\n",
    "#     scores = bm25.get_scores(claim.split())\n",
    "    \n",
    "#     # -------- 4b.  SBERT ranking ----------\n",
    "#     # Claim embedding\n",
    "#     claim_emb = bert_model.encode(claim, convert_to_tensor=True, normalize_embeddings=True)\n",
    "#     sbert_embs = bert_model.encode(context_sentences, convert_to_tensor=True,\n",
    "#                                    normalize_embeddings=True)\n",
    "#     cos_scores = util.cos_sim(claim_emb, sbert_embs).squeeze(0).cpu().numpy()\n",
    "    \n",
    "#     # Chọn baseline nào?\n",
    "#     # Uncomment 1 trong 2 dòng dưới:\n",
    "#     ranking_scores = scores         # BM25\n",
    "#     # ranking_scores = cos_scores   # SBERT\n",
    "    \n",
    "#     # Xếp hạng giảm dần\n",
    "#     ranked_ids = np.argsort(ranking_scores)[::-1]    # index sau sắp xếp\n",
    "#     ranked_sents = [context_sentences[i] for i in ranked_ids]\n",
    "    \n",
    "#     # Vị trí evidence\n",
    "#     rank = None\n",
    "#     for idx, sent in enumerate(ranked_sents, 1):   # start=1\n",
    "#         if sent == gold:\n",
    "#             rank = idx\n",
    "#             break\n",
    "    \n",
    "#     # Cộng dồn metric\n",
    "#     hit1, mrr, recalls = calc_metrics(rank)\n",
    "#     metrics_sum['hit1']       += hit1\n",
    "#     metrics_sum['mrr']        += mrr\n",
    "#     metrics_sum['recall@3']   += recalls[3]\n",
    "#     metrics_sum['recall@5']   += recalls[5]\n",
    "\n",
    "# #############################################################\n",
    "# # 5. Kết quả trung bình\n",
    "# #############################################################\n",
    "# print(\"========= Baseline results =========\")\n",
    "# print(f\"Queries evaluated      : {N}\")\n",
    "# print(f\"Hit@1 (Accuracy)       : {metrics_sum['hit1']/N:.4f}\")\n",
    "# print(f\"MRR                    : {metrics_sum['mrr']/N:.4f}\")\n",
    "# print(f\"Recall@3               : {metrics_sum['recall@3']/N:.4f}\")\n",
    "# print(f\"Recall@5               : {metrics_sum['recall@5']/N:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2aa1bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing context cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25384/25384 [13:01<00:00, 32.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding all claims ...\n",
      "Evaluating with 16 threads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25384/25384 [00:04<00:00, 5401.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= BASELINE (Thread) =============\n",
      "Queries evaluated : 25384\n",
      "Hit@1             : 0.3025\n",
      "MRR               : 0.3163\n",
      "Recall@3          : 0.3259\n",
      "Recall@5          : 0.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install rank_bm25 sentence-transformers underthesea tqdm\n",
    "import hashlib, os, json, numpy as np, tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from underthesea import word_tokenize          # tokenizer tiếng Việt\n",
    "\n",
    "# --------------------- 0. HÀM TIỆN ÍCH ---------------------------\n",
    "def tokenize(sent: str):\n",
    "    \"\"\"Tách từ, trả list token (giữ dấu _).\"\"\"\n",
    "    return word_tokenize(sent, format=\"text\").split()\n",
    "\n",
    "def hash_ctx(sents):\n",
    "    return hashlib.md5(\" \".join(sents).encode()).hexdigest()\n",
    "\n",
    "def calc_single_metrics(rank):\n",
    "    \"\"\"Trả hit@1, mrr, recall3, recall5 cho 1 query.\"\"\"\n",
    "    hit1  = 1 if rank == 1 else 0\n",
    "    mrr   = 1.0 / rank if rank else 0.0\n",
    "    rec3  = 1 if rank and rank <= 3 else 0\n",
    "    rec5  = 1 if rank and rank <= 5 else 0\n",
    "    return hit1, mrr, rec3, rec5\n",
    "\n",
    "# --------------------- 1. LOAD & CACHE ---------------------------\n",
    "# new_data = [...]   # list các dict (context, claim, evidence, verdict)\n",
    "dataset_raw = dataset\n",
    "\n",
    "bert = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "context_cache = {}      # cid -> dict(sentences, bm25, emb)\n",
    "claims        = []      # giữ thứ tự với dataset_idx\n",
    "dataset       = []      # bản ghi kèm cid\n",
    "\n",
    "print(\"Pre-computing context cache ...\")\n",
    "for item in tqdm.tqdm(dataset_raw):\n",
    "    cid = hash_ctx(item['context'])\n",
    "    if cid not in context_cache:\n",
    "        sents = [s.strip() for s in item['context']]\n",
    "        bm25  = BM25Okapi([tokenize(s) for s in sents])\n",
    "        emb   = bert.encode(sents,\n",
    "                            batch_size=128,\n",
    "                            convert_to_tensor=True,\n",
    "                            normalize_embeddings=True)\n",
    "        context_cache[cid] = {\"sents\": sents, \"bm25\": bm25, \"emb\": emb}\n",
    "    dataset.append({**item, \"cid\": cid})\n",
    "    claims.append(item['claim'].strip())\n",
    "\n",
    "print(\"Encoding all claims ...\")\n",
    "claim_embs = bert.encode(claims,\n",
    "                         batch_size=128,\n",
    "                         convert_to_tensor=True,\n",
    "                         normalize_embeddings=True)\n",
    "\n",
    "# --------------------- 2. HÀM CHẠY CHO 1 CLAIM -------------------\n",
    "def evaluate_idx(idx: int):\n",
    "    ex          = dataset[idx]\n",
    "    cid         = ex[\"cid\"]\n",
    "    ctx         = context_cache[cid]\n",
    "    gold_sent   = ex[\"evidence\"].strip()\n",
    "\n",
    "    # ---- BM25 (đổi sang cos_scores nếu muốn SBERT) ---------------\n",
    "    bm25_scores = ctx[\"bm25\"].get_scores(tokenize(ex[\"claim\"]))\n",
    "    ranking     = bm25_scores            # hoặc util.cos_sim(...)\n",
    "    ranked_ids  = np.argsort(ranking)[::-1]\n",
    "\n",
    "    # ---- tìm vị trí câu evidence -------------------------------\n",
    "    rank = None\n",
    "    for pos, sent_id in enumerate(ranked_ids, 1):     # start at 1\n",
    "        if ctx[\"sents\"][sent_id] == gold_sent:\n",
    "            rank = pos\n",
    "            break\n",
    "    return calc_single_metrics(rank)\n",
    "\n",
    "# --------------------- 3. CHẠY ĐA LUỒNG --------------------------\n",
    "num_workers = min(16, os.cpu_count()*2)   # ví dụ: gấp đôi core\n",
    "metrics_sum = np.zeros(4, dtype=float)    # [hit1, mrr, rec3, rec5]\n",
    "\n",
    "print(f\"Evaluating with {num_workers} threads ...\")\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as pool:\n",
    "    futures = [pool.submit(evaluate_idx, i) for i in range(len(dataset))]\n",
    "    for fut in tqdm.tqdm(as_completed(futures), total=len(dataset)):\n",
    "        metrics_sum += np.array(fut.result())\n",
    "\n",
    "N = len(dataset)\n",
    "print(\"\\n============= BASELINE (Thread) =============\")\n",
    "print(f\"Queries evaluated : {N}\")\n",
    "print(f\"Hit@1             : {metrics_sum[0]/N:.4f}\")\n",
    "print(f\"MRR               : {metrics_sum[1]/N:.4f}\")\n",
    "print(f\"Recall@3          : {metrics_sum[2]/N:.4f}\")\n",
    "print(f\"Recall@5          : {metrics_sum[3]/N:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb59190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing context cache ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25384/25384 [13:37<00:00, 31.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding all claims ...\n",
      "Evaluating with 16 threads ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25384/25384 [00:03<00:00, 7943.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= BASELINE (Thread) =============\n",
      "Queries evaluated : 25384\n",
      "Hit@1             : 0.2812\n",
      "MRR               : 0.2995\n",
      "Recall@3          : 0.3104\n",
      "Recall@5          : 0.3204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install rank_bm25 sentence-transformers underthesea tqdm\n",
    "import hashlib, os, json, numpy as np, tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from underthesea import word_tokenize          # tokenizer tiếng Việt\n",
    "\n",
    "# --------------------- 0. HÀM TIỆN ÍCH ---------------------------\n",
    "def tokenize(sent: str):\n",
    "    \"\"\"Tách từ, trả list token (giữ dấu _).\"\"\"\n",
    "    return word_tokenize(sent, format=\"text\").split()\n",
    "\n",
    "def hash_ctx(sents):\n",
    "    return hashlib.md5(\" \".join(sents).encode()).hexdigest()\n",
    "\n",
    "def calc_single_metrics(rank):\n",
    "    \"\"\"Trả hit@1, mrr, recall3, recall5 cho 1 query.\"\"\"\n",
    "    hit1  = 1 if rank == 1 else 0\n",
    "    mrr   = 1.0 / rank if rank else 0.0\n",
    "    rec3  = 1 if rank and rank <= 3 else 0\n",
    "    rec5  = 1 if rank and rank <= 5 else 0\n",
    "    return hit1, mrr, rec3, rec5\n",
    "\n",
    "# --------------------- 1. LOAD & CACHE ---------------------------\n",
    "# new_data = [...]   # list các dict (context, claim, evidence, verdict)\n",
    "dataset_raw = dataset\n",
    "\n",
    "bert = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "context_cache = {}      # cid -> dict(sentences, bm25, emb)\n",
    "claims        = []      # giữ thứ tự với dataset_idx\n",
    "dataset       = []      # bản ghi kèm cid\n",
    "\n",
    "print(\"Pre-computing context cache ...\")\n",
    "for item in tqdm.tqdm(dataset_raw):\n",
    "    cid = hash_ctx(item['context'])\n",
    "    if cid not in context_cache:\n",
    "        sents = [s.strip() for s in item['context']]\n",
    "        bm25  = BM25Okapi([tokenize(s) for s in sents])\n",
    "        emb   = bert.encode(sents,\n",
    "                            batch_size=128,\n",
    "                            convert_to_tensor=True,\n",
    "                            normalize_embeddings=True)\n",
    "        context_cache[cid] = {\"sents\": sents, \"bm25\": bm25, \"emb\": emb}\n",
    "    dataset.append({**item, \"cid\": cid})\n",
    "    claims.append(item['claim'].strip())\n",
    "\n",
    "print(\"Encoding all claims ...\")\n",
    "claim_embs = bert.encode(claims,\n",
    "                         batch_size=128,\n",
    "                         convert_to_tensor=True,\n",
    "                         normalize_embeddings=True)\n",
    "\n",
    "# --------------------- 2. HÀM CHẠY CHO 1 CLAIM -------------------\n",
    "def evaluate_idx(idx: int):\n",
    "    ex          = dataset[idx]\n",
    "    cid         = ex[\"cid\"]\n",
    "    ctx         = context_cache[cid]\n",
    "    gold_sent   = ex[\"evidence\"].strip()\n",
    "\n",
    "    # ---- BM25 (đổi sang cos_scores nếu muốn SBERT) ---------------\n",
    "    cos_scores  = util.cos_sim(claim_embs[idx], ctx[\"emb\"]).squeeze(0).cpu().numpy()\n",
    "    ranking     = cos_scores\n",
    "    ranked_ids  = np.argsort(ranking)[::-1]\n",
    "\n",
    "    # ---- tìm vị trí câu evidence -------------------------------\n",
    "    rank = None\n",
    "    for pos, sent_id in enumerate(ranked_ids, 1):     # start at 1\n",
    "        if ctx[\"sents\"][sent_id] == gold_sent:\n",
    "            rank = pos\n",
    "            break\n",
    "    return calc_single_metrics(rank)\n",
    "\n",
    "# --------------------- 3. CHẠY ĐA LUỒNG --------------------------\n",
    "num_workers = min(16, os.cpu_count()*2)   # ví dụ: gấp đôi core\n",
    "metrics_sum = np.zeros(4, dtype=float)    # [hit1, mrr, rec3, rec5]\n",
    "\n",
    "print(f\"Evaluating with {num_workers} threads ...\")\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as pool:\n",
    "    futures = [pool.submit(evaluate_idx, i) for i in range(len(dataset))]\n",
    "    for fut in tqdm.tqdm(as_completed(futures), total=len(dataset)):\n",
    "        metrics_sum += np.array(fut.result())\n",
    "\n",
    "N = len(dataset)\n",
    "print(\"\\n============= BASELINE (Thread) =============\")\n",
    "print(f\"Queries evaluated : {N}\")\n",
    "print(f\"Hit@1             : {metrics_sum[0]/N:.4f}\")\n",
    "print(f\"MRR               : {metrics_sum[1]/N:.4f}\")\n",
    "print(f\"Recall@3          : {metrics_sum[2]/N:.4f}\")\n",
    "print(f\"Recall@5          : {metrics_sum[3]/N:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c0a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
