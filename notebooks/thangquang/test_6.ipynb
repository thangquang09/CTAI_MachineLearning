{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b58e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from bert_logistic import read_texts_from_dir\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2314b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "# Tải mô hình spacy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Mô hình 'en_core_web_sm' chưa được tải. Vui lòng chạy:\")\n",
    "    print(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c5f2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Number of directories: 95\n",
      "Number of directories: 1068\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train\"\n",
    "test_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/test\"\n",
    "gt_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    "print(\"Loading data...\")\n",
    "df_train = read_texts_from_dir(train_path)\n",
    "df_test = read_texts_from_dir(test_path)\n",
    "df_train_gt = pd.read_csv(gt_path)\n",
    "y_train = df_train_gt[\"real_text_id\"].values\n",
    "\n",
    "df_train.rename(columns={\"file_1\": \"text_0\", \"file_2\": \"text_1\"}, inplace=True)\n",
    "df_test.rename(columns={\"file_1\": \"text_0\", \"file_2\": \"text_1\"}, inplace=True)\n",
    "df_train[\"label\"] = df_train_gt[\"real_text_id\"]\n",
    "\n",
    "df_train[\"label\"] = df_train[\"label\"].map({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a5041cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word_count_text_0'] = df_train['text_0'].apply(lambda x: len(word_tokenize(x)))\n",
    "df_train['word_count_text_1'] = df_train['text_1'].apply(lambda x: len(word_tokenize(x)))\n",
    "\n",
    "df_train['sentence_count_text_0'] = df_train['text_0'].apply(lambda x: len(sent_tokenize(x)))\n",
    "df_train['sentence_count_text_1'] = df_train['text_1'].apply(lambda x: len(sent_tokenize(x)))\n",
    "\n",
    "df_train['ner_count_text_0'] = df_train['text_0'].apply(lambda x: len(nlp(x).ents))\n",
    "df_train['ner_count_text_1'] = df_train['text_1'].apply(lambda x: len(nlp(x).ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca6d9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các ngưỡng bạn đã chọn (hoặc từ Decision Tree)\n",
    "THRESHOLDS = {\n",
    "    'word_count_max': 550,\n",
    "    'word_count_min': 80,\n",
    "    'sentence_count_max': 25,\n",
    "    'sentence_count_min': 2,\n",
    "    'ner_count_max': 58\n",
    "}\n",
    "\n",
    "def is_abnormal(word_count, sentence_count, ner_count, thresholds):\n",
    "    \"\"\"Kiểm tra một văn bản có đặc điểm bất thường không. Trả về True/False.\"\"\"\n",
    "    if word_count > thresholds['word_count_max'] or word_count < thresholds['word_count_min']:\n",
    "        return True\n",
    "    if sentence_count > thresholds['sentence_count_max'] or sentence_count < thresholds['sentence_count_min']:\n",
    "        return True\n",
    "    if ner_count > thresholds['ner_count_max']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def hybrid_classifier_logic(row, thresholds):\n",
    "    \"\"\"\n",
    "    Áp dụng logic lai cho một hàng dữ liệu.\n",
    "    - Trả về 0 hoặc 1 nếu quy tắc có thể quyết định.\n",
    "    - Trả về -1 (hoặc None) nếu là trường hợp khó, cần mô hình ML.\n",
    "    \"\"\"\n",
    "    # Trích xuất các feature đã được tính toán sẵn trong DataFrame của bạn\n",
    "    # (Giả sử bạn đã chạy hàm create_numerical_features và có các cột này)\n",
    "    features_0 = (row.word_count_text_0, row.sentence_count_text_0, row.ner_count_text_0)\n",
    "    features_1 = (row.word_count_text_1, row.sentence_count_text_1, row.ner_count_text_1)\n",
    "\n",
    "    # Áp dụng bộ lọc\n",
    "    is_abnormal_0 = is_abnormal(*features_0, thresholds)\n",
    "    is_abnormal_1 = is_abnormal(*features_1, thresholds)\n",
    "\n",
    "    # Áp dụng logic\n",
    "    if is_abnormal_0 and not is_abnormal_1:\n",
    "        # text_0 là FAKE, text_1 là REAL -> dự đoán nhãn là 1\n",
    "        return 1\n",
    "    elif not is_abnormal_0 and is_abnormal_1:\n",
    "        # text_0 là REAL, text_1 là FAKE -> dự đoán nhãn là 0\n",
    "        return 0\n",
    "    else:\n",
    "        # Cả hai đều bình thường, HOẶC cả hai đều bất thường.\n",
    "        # Đây là trường hợp \"khó\", cần mô hình ML xử lý.\n",
    "        return -1 # Dùng -1 để đánh dấu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d1d51f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 10)\n"
     ]
    }
   ],
   "source": [
    "df_train['initial_prediction'] = df_train.apply(lambda row: hybrid_classifier_logic(row, THRESHOLDS), axis=1)\n",
    "\n",
    "ambiguous_indices = df_train[df_train['initial_prediction'] == -1].index\n",
    "\n",
    "df_model = df_train.loc[ambiguous_indices]\n",
    "print(df_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9072d66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>initial_prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  initial_prediction\n",
       "id                           \n",
       "4       1                   1\n",
       "10      0                   0\n",
       "12      0                   0\n",
       "14      1                   1\n",
       "16      0                   0\n",
       "34      1                   1\n",
       "40      0                   0\n",
       "45      1                   1\n",
       "55      1                   1\n",
       "57      0                   0\n",
       "60      1                   1\n",
       "61      0                   0\n",
       "62      1                   1\n",
       "63      1                   1\n",
       "66      0                   0\n",
       "68      1                   1\n",
       "71      1                   1\n",
       "72      0                   0\n",
       "73      0                   0\n",
       "76      1                   1\n",
       "79      0                   0\n",
       "80      1                   1\n",
       "83      1                   1\n",
       "84      1                   1\n",
       "86      1                   1\n",
       "87      1                   1\n",
       "88      0                   0\n",
       "89      1                   1\n",
       "92      1                   1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['initial_prediction'] != -1][['label', 'initial_prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ad5a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Since its launch in '99, the Very Large Telesc...</td>\n",
       "      <td>AssemblyCulture AssemblyCulture AssemblyCultur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_1  \\\n",
       "id                                                      \n",
       "0   The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1   China\\nThe goal of this project involves achie...   \n",
       "2   Scientists can learn about how galaxies form a...   \n",
       "3   China\\nThe study suggests that multiple star s...   \n",
       "5   Since its launch in '99, the Very Large Telesc...   \n",
       "\n",
       "                                               file_2  label  \n",
       "id                                                            \n",
       "0   The China relay network has released a signifi...      0  \n",
       "1   The project aims to achieve an accuracy level ...      1  \n",
       "2   Dinosaur eggshells offer clues about what dino...      0  \n",
       "3   The importance for understanding how stars evo...      1  \n",
       "5   AssemblyCulture AssemblyCulture AssemblyCultur...      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = df_model[['text_0', 'text_1', 'label']]\n",
    "y = df_model['label']\n",
    "df_model.rename(columns={\"text_0\": \"file_1\", \"text_1\": \"file_2\"}, inplace=True)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b99d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_logistic import prepare_data_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75aacd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracting top importance features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting top features: 100%|██████████| 66/66 [00:00<00:00, 393.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 66/66 [00:00<00:00, 242.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Extracting pairwise features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pairwise features: 100%|██████████| 66/66 [00:00<00:00, 547.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Combining features...\n",
      "Final feature matrix shape: (66, 1654)\n",
      "Top features: 25, Rule: 78, Stat: 6, Embedding: 1538, Pairwise: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, embedding_extractor = prepare_data_for_model(\n",
    "    df_model, \n",
    "    fit_embedding=True, \n",
    "    model_name='intfloat/multilingual-e5-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34610a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a789d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with CatBoost: 0.9286\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "catboost_model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "\n",
    "# Train the model\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_preds_val_catboost = catboost_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc_catboost = accuracy_score(y_val, y_preds_val_catboost)\n",
    "print(f\"Validation accuracy with CatBoost: {acc_catboost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5c593ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BƯỚC 1: Tải và chuẩn bị dữ liệu ---\n",
      "Number of directories: 95\n",
      "Number of directories: 1068\n",
      "✅ Dữ liệu đã sẵn sàng.\n",
      "\n",
      "--- BƯỚC 2: Áp dụng bộ lọc Rule-Based cho tập Train ---\n",
      "✅ Đã tách được 66 mẫu 'khó' từ tập train để huấn luyện model.\n",
      "\n",
      "--- BƯỚC 3: Huấn luyện mô hình CatBoost cuối cùng ---\n",
      "Step 1: Extracting top importance features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting top features: 100%|██████████| 66/66 [00:00<00:00, 556.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 66/66 [00:00<00:00, 253.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Extracting pairwise features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pairwise features: 100%|██████████| 66/66 [00:00<00:00, 550.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Combining features...\n",
      "Final feature matrix shape: (66, 1654)\n",
      "Top features: 25, Rule: 78, Stat: 6, Embedding: 1538, Pairwise: 7\n",
      "✅ Huấn luyện mô hình CatBoost cuối cùng hoàn tất.\n",
      "\n",
      "--- BƯỚC 4: Áp dụng Hybrid Approach cho tập Test ---\n",
      "Bộ lọc Rule-based đã xử lý 249 mẫu 'dễ' trên tập test.\n",
      "Còn lại 819 mẫu 'khó' cần mô hình ML xử lý.\n",
      "Step 1: Extracting top importance features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting top features: 100%|██████████| 819/819 [00:01<00:00, 582.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting rule-based features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting rule-based features: 100%|██████████| 819/819 [00:03<00:00, 262.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Extracting statistical features...\n",
      "Step 4: Extracting embedding features...\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 13/13 [00:45<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 13/13 [00:45<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Extracting pairwise features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting pairwise features: 100%|██████████| 819/819 [00:01<00:00, 549.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Combining features...\n",
      "Final feature matrix shape: (819, 1654)\n",
      "Top features: 25, Rule: 78, Stat: 6, Embedding: 1538, Pairwise: 7\n",
      "✅ Dự đoán cho các mẫu 'khó' hoàn tất.\n",
      "\n",
      "--- BƯỚC 5: Tạo file submission ---\n",
      "✅ Đã tạo file submission.csv thành công!\n",
      "   id  real_text_id\n",
      "0   0             2\n",
      "1   1             2\n",
      "2   2             1\n",
      "3   3             1\n",
      "4   4             2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Giả sử các file và hàm custom của bạn đã có sẵn\n",
    "from bert_logistic import read_texts_from_dir, prepare_data_for_model\n",
    "\n",
    "# === BƯỚC 1: TẢI DỮ LIỆU VÀ CHUẨN BỊ BAN ĐẦU ===\n",
    "\n",
    "print(\"--- BƯỚC 1: Tải và chuẩn bị dữ liệu ---\")\n",
    "# Tải dữ liệu train và test\n",
    "train_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train\"\n",
    "test_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/test\"\n",
    "gt_path = \"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    "\n",
    "df_train = read_texts_from_dir(train_path)\n",
    "df_test = read_texts_from_dir(test_path)\n",
    "df_train_gt = pd.read_csv(gt_path)\n",
    "\n",
    "# Gán nhãn và đổi tên cột\n",
    "df_train.rename(columns={\"file_1\": \"text_0\", \"file_2\": \"text_1\"}, inplace=True)\n",
    "df_test.rename(columns={\"file_1\": \"text_0\", \"file_2\": \"text_1\"}, inplace=True)\n",
    "df_train[\"label\"] = df_train_gt[\"real_text_id\"].map({1: 0, 2: 1})\n",
    "\n",
    "# Tải mô hình spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"✅ Dữ liệu đã sẵn sàng.\")\n",
    "\n",
    "# === BƯỚC 2 (ĐÃ CẬP NHẬT): ÁP DỤNG BỘ LỌC RULE-BASED VỚI LOGIC RÕ RÀNG HƠN ===\n",
    "\n",
    "print(\"\\n--- BƯỚC 2: Áp dụng bộ lọc Rule-Based cho tập Train ---\")\n",
    "# Tính các feature cơ bản cho việc lọc (giữ nguyên)\n",
    "df_train['word_count_text_0'] = df_train['text_0'].apply(lambda x: len(word_tokenize(x)))\n",
    "df_train['word_count_text_1'] = df_train['text_1'].apply(lambda x: len(word_tokenize(x)))\n",
    "df_train['sentence_count_text_0'] = df_train['text_0'].apply(lambda x: len(sent_tokenize(x)))\n",
    "df_train['sentence_count_text_1'] = df_train['text_1'].apply(lambda x: len(sent_tokenize(x)))\n",
    "df_train['ner_count_text_0'] = df_train['text_0'].apply(lambda x: len(nlp(x).ents))\n",
    "df_train['ner_count_text_1'] = df_train['text_1'].apply(lambda x: len(nlp(x).ents))\n",
    "\n",
    "# Định nghĩa lại các hàm lọc (giữ nguyên)\n",
    "THRESHOLDS = {'word_count_max': 550, 'word_count_min': 80, 'sentence_count_max': 25, 'sentence_count_min': 2, 'ner_count_max': 58}\n",
    "def is_abnormal(wc, sc, nc, t):\n",
    "    if wc > t['word_count_max'] or wc < t['word_count_min']: return True\n",
    "    if sc > t['sentence_count_max'] or sc < t['sentence_count_min']: return True\n",
    "    if nc > t['ner_count_max']: return True\n",
    "    return False\n",
    "\n",
    "# ----- THAY THẾ BẰNG PHIÊN BẢN LOGIC V2 RÕ RÀNG HƠN -----\n",
    "def hybrid_classifier_logic_v2(row, thresholds):\n",
    "    \"\"\"\n",
    "    Phiên bản logic lai rõ ràng hơn để thể hiện tính đối xứng.\n",
    "    \"\"\"\n",
    "    features_0 = (row.word_count_text_0, row.sentence_count_text_0, row.ner_count_text_0)\n",
    "    features_1 = (row.word_count_text_1, row.sentence_count_text_1, row.ner_count_text_1)\n",
    "\n",
    "    is_abnormal_0 = is_abnormal(*features_0, thresholds)\n",
    "    is_abnormal_1 = is_abnormal(*features_1, thresholds)\n",
    "\n",
    "    # TRƯỜNG HỢP 1: Quy tắc có thể quyết định rõ ràng (chỉ một bên bất thường)\n",
    "    if is_abnormal_0 != is_abnormal_1:\n",
    "        if is_abnormal_0:\n",
    "            # text_0 bất thường (FAKE), vậy text_1 là REAL -> dự đoán 1\n",
    "            return 1\n",
    "        else: # is_abnormal_1 là True\n",
    "            # text_1 bất thường (FAKE), vậy text_0 là REAL -> dự đoán 0\n",
    "            return 0\n",
    "            \n",
    "    # TRƯỜNG HỢP 2: Quy tắc không thể quyết định (cả hai cùng bình thường hoặc cùng bất thường)\n",
    "    else:\n",
    "        return -1 # Cần mô hình ML\n",
    "# ----- KẾT THÚC PHẦN THAY THẾ -----\n",
    "\n",
    "# Tách ra các mẫu \"khó\" để huấn luyện mô hình ML\n",
    "# Sử dụng hàm logic v2 mới\n",
    "df_train['initial_prediction'] = df_train.apply(lambda row: hybrid_classifier_logic_v2(row, THRESHOLDS), axis=1)\n",
    "ambiguous_train_indices = df_train[df_train['initial_prediction'] == -1].index\n",
    "df_model_train = df_train.loc[ambiguous_train_indices][['text_0', 'text_1', 'label']]\n",
    "df_model_train.rename(columns={\"text_0\": \"file_1\", \"text_1\": \"file_2\"}, inplace=True)\n",
    "y_model_train = df_model_train['label']\n",
    "\n",
    "print(f\"✅ Đã tách được {len(df_model_train)} mẫu 'khó' từ tập train để huấn luyện model.\")\n",
    "\n",
    "# === BƯÓC 3: HUẤN LUYỆN MODEL CUỐI CÙNG ===\n",
    "\n",
    "print(\"\\n--- BƯỚC 3: Huấn luyện mô hình CatBoost cuối cùng ---\")\n",
    "# Chuẩn bị dữ liệu train cho model bằng hàm của bạn\n",
    "# 'fit_embedding=True' để huấn luyện extractor trên dữ liệu này\n",
    "X_model_train, embedding_extractor = prepare_data_for_model(\n",
    "    df_model_train,\n",
    "    fit_embedding=True,\n",
    "    model_name='intfloat/multilingual-e5-small'\n",
    ")\n",
    "\n",
    "# Huấn luyện model trên toàn bộ 66 mẫu \"khó\"\n",
    "final_catboost_model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=6, verbose=0, random_state=42)\n",
    "final_catboost_model.fit(X_model_train, y_model_train)\n",
    "print(\"✅ Huấn luyện mô hình CatBoost cuối cùng hoàn tất.\")\n",
    "\n",
    "# === BƯỚC 4 (ĐÃ CẬP NHẬT): ÁP DỤNG HYBRID APPROACH CHO TẬP TEST ===\n",
    "\n",
    "print(\"\\n--- BƯỚC 4: Áp dụng Hybrid Approach cho tập Test ---\")\n",
    "# Ensure all required features are computed for df_test\n",
    "df_test['sentence_count_text_0'] = df_test['text_0'].apply(lambda x: len(sent_tokenize(x)))\n",
    "df_test['sentence_count_text_1'] = df_test['text_1'].apply(lambda x: len(sent_tokenize(x)))\n",
    "df_test['word_count_text_1'] = df_test['text_1'].apply(lambda x: len(word_tokenize(x)))\n",
    "df_test['word_count_text_0'] = df_test['text_0'].apply(lambda x: len(word_tokenize(x)))\n",
    "df_test['ner_count_text_0'] = df_test['text_0'].apply(lambda x: len(nlp(x).ents))\n",
    "df_test['ner_count_text_1'] = df_test['text_1'].apply(lambda x: len(nlp(x).ents))\n",
    "\n",
    "# 4b. Áp dụng bộ lọc rule-based (sử dụng hàm v2)\n",
    "df_test['prediction'] = df_test.apply(lambda row: hybrid_classifier_logic_v2(row, THRESHOLDS), axis=1)\n",
    "ambiguous_test_indices = df_test[df_test['prediction'] == -1].index\n",
    "df_model_test = df_test.loc[ambiguous_test_indices][['text_0', 'text_1']]\n",
    "df_model_test.rename(columns={\"text_0\": \"file_1\", \"text_1\": \"file_2\"}, inplace=True)\n",
    "\n",
    "\n",
    "print(f\"Bộ lọc Rule-based đã xử lý {len(df_test) - len(df_model_test)} mẫu 'dễ' trên tập test.\")\n",
    "print(f\"Còn lại {len(df_model_test)} mẫu 'khó' cần mô hình ML xử lý.\")\n",
    "\n",
    "# 4c. Dùng model ML cho các trường hợp \"khó\"\n",
    "if not df_model_test.empty:\n",
    "    # Chuẩn bị dữ liệu test cho model\n",
    "    # 'fit_embedding=False' và truyền extractor đã được huấn luyện\n",
    "    X_model_test, _ = prepare_data_for_model(\n",
    "        df_model_test,\n",
    "        fit_embedding=False,\n",
    "        embedding_extractor=embedding_extractor\n",
    "    )\n",
    "    \n",
    "    # Dự đoán\n",
    "    ml_predictions = final_catboost_model.predict(X_model_test)\n",
    "    \n",
    "    # Cập nhật kết quả dự đoán\n",
    "    df_test.loc[ambiguous_test_indices, 'prediction'] = ml_predictions\n",
    "print(\"✅ Dự đoán cho các mẫu 'khó' hoàn tất.\")\n",
    "\n",
    "\n",
    "# === BƯỚC 5: TẠO FILE SUBMISSION ===\n",
    "print(\"\\n--- BƯỚC 5: Tạo file submission ---\")\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df['id'] = df_test.index\n",
    "submission_df['real_text_id'] = df_test['prediction'].astype(int)\n",
    "\n",
    "# Chuyển nhãn từ (0, 1) trở lại (1, 2)\n",
    "submission_df['real_text_id'] = submission_df['real_text_id'].map({0: 1, 1: 2})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"✅ Đã tạo file submission.csv thành công!\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
