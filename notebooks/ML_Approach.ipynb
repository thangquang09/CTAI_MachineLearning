{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b0e4b9",
   "metadata": {},
   "source": [
    "## I. Read Data (Only Statistic Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "562c7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Train: (152, 45)\n",
      "Shape Validation: (19, 45)\n",
      "Columns Train: Index(['file_1', 'file_2', 'label', 'file1_char_count', 'file1_word_count',\n",
      "       'file1_sentence_count', 'file1_avg_sentence_length',\n",
      "       'file1_english_word_ratio', 'file1_has_non_english_script',\n",
      "       'file1_has_mixed_scripts', 'file1_unicode_control_chars',\n",
      "       'file1_num_count', 'file1_repetition_score', 'file1_perplexity_score',\n",
      "       'file1_ttr_ratio', 'file2_char_count', 'file2_word_count',\n",
      "       'file2_sentence_count', 'file2_avg_sentence_length',\n",
      "       'file2_english_word_ratio', 'file2_has_non_english_script',\n",
      "       'file2_has_mixed_scripts', 'file2_unicode_control_chars',\n",
      "       'file2_num_count', 'file2_repetition_score', 'file2_perplexity_score',\n",
      "       'file2_ttr_ratio', 'diff_char_count', 'ratio_char_count',\n",
      "       'diff_word_count', 'ratio_word_count', 'diff_sentence_count',\n",
      "       'ratio_sentence_count', 'diff_avg_sentence_length',\n",
      "       'diff_english_word_ratio', 'diff_has_non_english_script',\n",
      "       'diff_has_mixed_scripts', 'diff_unicode_control_chars',\n",
      "       'diff_num_count', 'diff_repetition_score', 'diff_perplexity_score',\n",
      "       'ratio_perplexity_score', 'diff_ttr_ratio', 'ratio_ttr_ratio',\n",
      "       'cosine_sim_word_counts'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Find project root directory automatically\n",
    "def find_project_root():\n",
    "    current_dir = os.getcwd()\n",
    "    while current_dir != '/':\n",
    "        if any(marker in os.listdir(current_dir) for marker in ['.gitignore', 'requirements.txt', 'setup.py', 'pyproject.toml']):\n",
    "            return current_dir\n",
    "        current_dir = os.path.dirname(current_dir)\n",
    "    return os.getcwd()  # fallback to current directory\n",
    "\n",
    "project_root = find_project_root()\n",
    "\n",
    "train_stat_df_path = os.path.join(project_root, 'data/train_statistic_features.csv')\n",
    "val_stat_df_path = os.path.join(project_root, 'data/val_statistic_features.csv')\n",
    "train_tfidf_df_path = os.path.join(project_root, 'data/train_tfidf_features.csv')\n",
    "val_tfidf_df_path = os.path.join(project_root, 'data/val_tfidf_features.csv')\n",
    "train_bow_df_path = os.path.join(project_root, 'data/train_bow_features.csv')\n",
    "val_bow_df_path = os.path.join(project_root, 'data/val_bow_features.csv')\n",
    "test_stat_df_path = os.path.join(project_root, 'data/test_statistic_features.csv')\n",
    "test_tfidf_df_path = os.path.join(project_root, 'data/test_tfidf_features.csv')\n",
    "test_bow_df_path = os.path.join(project_root, 'data/test_bow_features.csv')\n",
    "\n",
    "train_stat_df = pd.read_csv(train_stat_df_path)\n",
    "val_stat_df = pd.read_csv(val_stat_df_path)\n",
    "test_stat_df = pd.read_csv(test_stat_df_path)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape Train:\", train_stat_df.shape)\n",
    "print(\"Shape Validation:\", val_stat_df.shape)\n",
    "print(\"Columns Train:\", train_stat_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157089a6",
   "metadata": {},
   "source": [
    "Có thể đọc mô tả các features ở [đây](../data/README.md#processed-features-information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc02778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_stat_df.drop(columns=[\"label\", \"file_1\", \"file_2\"]), train_stat_df[\"label\"]\n",
    "X_val, y_val = val_stat_df.drop(columns=[\"label\", \"file_1\", \"file_2\"]), val_stat_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4770863",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a0e1399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns with all zeros: 0\n",
      "Zero columns: []\n",
      "\n",
      "Columns with >90% zeros:\n",
      "diff_sentence_count             98.684211\n",
      "file1_has_mixed_scripts         90.131579\n",
      "file1_has_non_english_script    90.131579\n",
      "file2_has_non_english_script    90.131579\n",
      "file2_has_mixed_scripts         90.131579\n",
      "diff_has_non_english_script     80.263158\n",
      "diff_has_mixed_scripts          80.263158\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for columns that contain only zeros\n",
    "zero_columns = (X_train == 0).all()\n",
    "zero_column_names = zero_columns[zero_columns].index.tolist()\n",
    "\n",
    "print(f\"Number of columns with all zeros: {len(zero_column_names)}\")\n",
    "print(f\"Zero columns: {zero_column_names}\")\n",
    "\n",
    "# Also check the percentage of zeros in each column\n",
    "zero_percentages = (X_train == 0).mean() * 100\n",
    "high_zero_columns = zero_percentages[zero_percentages > 70].sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nColumns with >90% zeros:\")\n",
    "print(high_zero_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c0976",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5265deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF MODEL PERFORMANCE (Sorted by Accuracy)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy\n",
       "lightgbm            0.894737\n",
       "SVC                 0.842105\n",
       "LogisticRegression  0.842105\n",
       "RandomForest        0.842105\n",
       "KNN                 0.842105\n",
       "catboost            0.842105\n",
       "xgboost             0.842105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from IPython.display import display\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'catboost': CatBoostClassifier(random_state=42, verbose=0),\n",
    "    'lightgbm': LGBMClassifier(random_state=42, verbose=0),\n",
    "    'xgboost': XGBClassifier(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "y_train = y_train - 1\n",
    "for model_name, model in models.items():\n",
    "    # print(f\"\\n{'='*50}\")\n",
    "    # print(f\"Training {model_name}\")\n",
    "    # print(f\"{'='*50}\")\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    y_pred = y_pred + 1\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame and sort by accuracy\n",
    "results_df = pd.DataFrame.from_dict(\n",
    "    {model: {'accuracy': result['accuracy']} for model, result in results.items()}, \n",
    "    orient='index'\n",
    ").sort_values('accuracy', ascending=False)\n",
    "\n",
    "# Summary of results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY OF MODEL PERFORMANCE (Sorted by Accuracy)\")\n",
    "print(f\"{'='*60}\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ffcb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_texts_from_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Reads the texts from a given directory and saves them in the pd.DataFrame with columns ['id', 'file_1', 'file_2'].\n",
    "\n",
    "    Params:\n",
    "      dir_path (str): path to the directory with data\n",
    "    \"\"\"\n",
    "    # Count number of directories in the provided path\n",
    "    dir_count = sum(\n",
    "        os.path.isdir(os.path.join(root, d))\n",
    "        for root, dirs, _ in os.walk(dir_path)\n",
    "        for d in dirs\n",
    "    )\n",
    "    data = [0 for _ in range(dir_count)]\n",
    "    print(f\"Number of directories: {dir_count}\")\n",
    "\n",
    "    # For each directory, read both file_1.txt and file_2.txt and save results to the list\n",
    "    i = 0\n",
    "    for folder_name in sorted(os.listdir(dir_path)):\n",
    "        folder_path = os.path.join(dir_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            try:\n",
    "                with open(\n",
    "                    os.path.join(folder_path, \"file_1.txt\"), \"r\", encoding=\"utf-8\"\n",
    "                ) as f1:\n",
    "                    text1 = f1.read().strip()\n",
    "                with open(\n",
    "                    os.path.join(folder_path, \"file_2.txt\"), \"r\", encoding=\"utf-8\"\n",
    "                ) as f2:\n",
    "                    text2 = f2.read().strip()\n",
    "                index = int(folder_name[-4:])\n",
    "                data[i] = (index, text1, text2)\n",
    "                i += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading directory {folder_name}: {e}\")\n",
    "\n",
    "    # Change list with results into pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"id\", \"file_1\", \"file_2\"]).set_index(\"id\")\n",
    "    return df\n",
    "    \n",
    "def make_submission(y_pred, file_name):\n",
    "    \n",
    "    from pathlib import Path\n",
    "    df_test = read_texts_from_dir(os.path.join(project_root, 'data/fake-or-real-the-impostor-hunt/data/test'))\n",
    "    # --- Build submission -------------------------------------------------\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": df_test.index,\n",
    "        \"real_text_id\": y_pred.astype(int)\n",
    "    }).sort_values(\"id\")\n",
    "    # submission['real_text_id'] = submission['real_text_id'].map({0: 1, 1: 2})\n",
    "\n",
    "\n",
    "    save_path = Path(f\"{file_name}.csv\")\n",
    "    submission.to_csv(save_path, index=False)\n",
    "    print(f\"✅ Submission saved to {save_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5621011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(test_stat_df.drop(columns=[\"file_1\", \"file_2\"]))\n",
    "y_pred = LGBMClassifier(random_state=42, verbose=0).fit(X_train_scaled, y_train).predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8adc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 1, 2, 1], shape=(1068,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1851442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 1068\n",
      "✅ Submission saved to /home/thangquang09/CODE/CTAI_MachineLearning/notebooks/test_pipeline.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "make_submission(y_pred, file_name='test_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ed7b4",
   "metadata": {},
   "source": [
    "## II. Data with TFIDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 92) (19, 92)\n"
     ]
    }
   ],
   "source": [
    "train_tfidf_df = pd.read_csv(train_tfidf_df_path)\n",
    "val_tfidf_df = pd.read_csv(val_tfidf_df_path)\n",
    "\n",
    "\n",
    "full_train_df = pd.concat([train_stat_df, train_tfidf_df], axis=1)\n",
    "full_val_df = pd.concat([val_stat_df, val_tfidf_df], axis=1)\n",
    "\n",
    "X_train, y_train = full_train_df.drop(columns=[\"label\"]), full_train_df[\"label\"]\n",
    "X_val, y_val = full_val_df.drop(columns=[\"label\"]), full_val_df[\"label\"]\n",
    "\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49955551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99827ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70ab15ac",
   "metadata": {},
   "source": [
    "## II. Data with BOW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c9cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 92) (19, 92)\n"
     ]
    }
   ],
   "source": [
    "train_bow_df = pd.read_csv(train_bow_df_path)\n",
    "val_bow_df = pd.read_csv(val_bow_df_path)\n",
    "\n",
    "full_train_df = pd.concat([train_stat_df, train_bow_df], axis=1)\n",
    "full_val_df = pd.concat([val_stat_df, val_bow_df], axis=1)\n",
    "\n",
    "X_train, y_train = full_train_df.drop(columns=[\"label\"]), full_train_df[\"label\"]\n",
    "X_val, y_val = full_val_df.drop(columns=[\"label\"]), full_val_df[\"label\"]\n",
    "\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374df47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddfafb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da14bf32",
   "metadata": {},
   "source": [
    "## Data with Pertained Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7dc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70f01887",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06012daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class UniversalEmbeddingExtractor:\n",
    "    def __init__(\n",
    "        self, model_name=\"bert-base-uncased\", max_length=512, device=None, batch_size=32\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.device = (\n",
    "            device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "\n",
    "        print(f\"Loading embedding model: {model_name}\")\n",
    "\n",
    "        # Detect model type and load accordingly\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load model based on model name/type.\"\"\"\n",
    "        model_name_lower = self.model_name.lower()\n",
    "\n",
    "        # Check if it's a sentence-transformers model\n",
    "        if any(\n",
    "            keyword in model_name_lower\n",
    "            for keyword in [\n",
    "                \"sentence-transformers\",\n",
    "                \"all-minilm\",\n",
    "                \"all-mpnet\",\n",
    "                \"bge-\",\n",
    "                \"e5-\",\n",
    "            ]\n",
    "        ):\n",
    "            self._load_sentence_transformer()\n",
    "        # Check if it's a Vietnamese model\n",
    "        elif any(\n",
    "            keyword in model_name_lower\n",
    "            for keyword in [\"vinai\", \"vietnamese\", \"phobert\"]\n",
    "        ):\n",
    "            self._load_transformers_model()\n",
    "        # Check if it's OpenAI model\n",
    "        elif \"openai\" in model_name_lower or \"text-embedding\" in model_name_lower:\n",
    "            self._load_openai_model()\n",
    "        # Default to transformers for BERT, RoBERTa, etc.\n",
    "        else:\n",
    "            self._load_transformers_model()\n",
    "\n",
    "    def _load_sentence_transformer(self):\n",
    "        \"\"\"Load sentence-transformers model.\"\"\"\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "\n",
    "            self.model_type = \"sentence_transformer\"\n",
    "            self.model = SentenceTransformer(self.model_name, device=self.device)\n",
    "            self.tokenizer = None  # Not needed for sentence-transformers\n",
    "            print(f\"Loaded as SentenceTransformer model\")\n",
    "        except ImportError:\n",
    "            print(\"sentence-transformers not installed, falling back to transformers\")\n",
    "            self._load_transformers_model()\n",
    "\n",
    "    def _load_transformers_model(self):\n",
    "        \"\"\"Load standard transformers model (BERT, RoBERTa, etc.).\"\"\"\n",
    "        self.model_type = \"transformers\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(f\"Loaded as Transformers model\")\n",
    "\n",
    "    def _load_openai_model(self):\n",
    "        \"\"\"Load OpenAI embedding model.\"\"\"\n",
    "        try:\n",
    "            import openai\n",
    "\n",
    "            self.model_type = \"openai\"\n",
    "            self.model = None  # Will use API\n",
    "            self.tokenizer = None\n",
    "            print(f\"Loaded as OpenAI model\")\n",
    "        except ImportError:\n",
    "            print(\"openai package not installed, falling back to transformers\")\n",
    "            self._load_transformers_model()\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        \"\"\"Extract embeddings for a list of texts using the appropriate method.\"\"\"\n",
    "        if self.model_type == \"sentence_transformer\":\n",
    "            return self._get_sentence_transformer_embeddings(texts)\n",
    "        elif self.model_type == \"transformers\":\n",
    "            return self._get_transformers_embeddings(texts)\n",
    "        elif self.model_type == \"openai\":\n",
    "            return self._get_openai_embeddings(texts)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
    "\n",
    "    def _get_sentence_transformer_embeddings(self, texts):\n",
    "        \"\"\"Extract embeddings using sentence-transformers.\"\"\"\n",
    "        embeddings = []\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(\n",
    "            range(0, len(texts), self.batch_size), desc=\"Extracting embeddings\"\n",
    "        ):\n",
    "            batch_texts = texts[i : i + self.batch_size]\n",
    "            batch_embeddings = self.model.encode(\n",
    "                batch_texts,\n",
    "                convert_to_tensor=False,\n",
    "                normalize_embeddings=True,\n",
    "                show_progress_bar=False,\n",
    "            )\n",
    "            embeddings.extend(batch_embeddings)\n",
    "\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def _get_transformers_embeddings(self, texts):\n",
    "        \"\"\"Extract embeddings using transformers (BERT-style).\"\"\"\n",
    "        embeddings = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for i in tqdm(\n",
    "                range(0, len(texts), self.batch_size), desc=\"Extracting embeddings\"\n",
    "            ):\n",
    "                batch_texts = texts[i : i + self.batch_size]\n",
    "                batch_embeddings = []\n",
    "\n",
    "                for text in batch_texts:\n",
    "                    # Tokenize\n",
    "                    inputs = self.tokenizer(\n",
    "                        text,\n",
    "                        max_length=self.max_length,\n",
    "                        truncation=True,\n",
    "                        padding=\"max_length\",\n",
    "                        return_tensors=\"pt\",\n",
    "                    )\n",
    "\n",
    "                    # Move to device\n",
    "                    inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "                    # Get embeddings\n",
    "                    outputs = self.model(**inputs)\n",
    "\n",
    "                    # Use [CLS] token embedding or mean pooling\n",
    "                    if hasattr(outputs, \"last_hidden_state\"):\n",
    "                        # For BERT-style models, use [CLS] token\n",
    "                        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                    elif hasattr(outputs, \"pooler_output\"):\n",
    "                        # Some models have pooler output\n",
    "                        cls_embedding = outputs.pooler_output.cpu().numpy()\n",
    "                    else:\n",
    "                        # Fallback: mean pooling\n",
    "                        cls_embedding = (\n",
    "                            outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "                        )\n",
    "\n",
    "                    batch_embeddings.append(cls_embedding.flatten())\n",
    "\n",
    "                embeddings.extend(batch_embeddings)\n",
    "\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def _get_openai_embeddings(self, texts):\n",
    "        \"\"\"Extract embeddings using OpenAI API.\"\"\"\n",
    "        import openai\n",
    "\n",
    "        embeddings = []\n",
    "\n",
    "        for i in tqdm(\n",
    "            range(0, len(texts), self.batch_size), desc=\"Extracting OpenAI embeddings\"\n",
    "        ):\n",
    "            batch_texts = texts[i : i + self.batch_size]\n",
    "\n",
    "            try:\n",
    "                response = openai.Embedding.create(\n",
    "                    model=self.model_name, input=batch_texts\n",
    "                )\n",
    "                batch_embeddings = [item[\"embedding\"] for item in response[\"data\"]]\n",
    "                embeddings.extend(batch_embeddings)\n",
    "            except Exception as e:\n",
    "                print(f\"Error with OpenAI API: {e}\")\n",
    "                # Fallback to zero embeddings\n",
    "                embeddings.extend(\n",
    "                    [np.zeros(1536) for _ in batch_texts]\n",
    "                )  # OpenAI default dim\n",
    "\n",
    "        return np.array(embeddings)\n",
    "\n",
    "\n",
    "def extract_embedding_features(\n",
    "    df: pd.DataFrame, embedding_extractor: UniversalEmbeddingExtractor\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Extract embedding features for both file_1 and file_2, including diff features.\"\"\"\n",
    "    print(\"Extracting embedding features for file_1...\")\n",
    "    emb_f1 = embedding_extractor.get_embeddings(df[\"file_1\"].tolist())\n",
    "\n",
    "    print(\"Extracting embedding features for file_2...\")\n",
    "    emb_f2 = embedding_extractor.get_embeddings(df[\"file_2\"].tolist())\n",
    "\n",
    "    # Create difference and similarity features\n",
    "    emb_diff = emb_f1 - emb_f2\n",
    "    emb_abs_diff = np.abs(emb_diff)\n",
    "\n",
    "    # Cosine similarity\n",
    "    cosine_sim = np.sum(emb_f1 * emb_f2, axis=1, keepdims=True) / (\n",
    "        np.linalg.norm(emb_f1, axis=1, keepdims=True)\n",
    "        * np.linalg.norm(emb_f2, axis=1, keepdims=True)\n",
    "        + 1e-8\n",
    "    )\n",
    "\n",
    "    # Euclidean distance\n",
    "    euclidean_dist = np.linalg.norm(emb_diff, axis=1, keepdims=True)\n",
    "\n",
    "    # Concatenate all embedding features\n",
    "    embedding_features = np.concatenate(\n",
    "        [emb_f1, emb_f2, emb_diff, emb_abs_diff, cosine_sim, euclidean_dist], axis=1\n",
    "    )\n",
    "\n",
    "    return embedding_features.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73cc39c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 5/5 [00:10<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 5/5 [00:10<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "embedding_features = extract_embedding_features(train_stat_df, embedding_extractor=UniversalEmbeddingExtractor(model_name='intfloat/multilingual-e5-small'))\n",
    "\n",
    "val_embedding_features = extract_embedding_features(val_stat_df, embedding_extractor=UniversalEmbeddingExtractor(model_name='intfloat/multilingual-e5-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8d38d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat with X_Train_scaled\n",
    "X_train_new = np.concatenate([X_train_scaled, embedding_features], axis=1)\n",
    "X_val_new = np.concatenate([X_val_scaled, val_embedding_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b660d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(random_state=42, verbose=0)\n",
    "model.fit(X_train_new, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val_new) + 1\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72d5b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c5d9818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes:\n",
      "train_stat_df: (152, 45)\n",
      "val_stat_df: (19, 45)\n",
      "\n",
      "Extracting embedding features...\n",
      "Loading embedding model: intfloat/multilingual-e5-small\n",
      "Loaded as SentenceTransformer model\n",
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 5/5 [00:10<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 5/5 [00:10<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embedding features for file_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embedding features shape: (152, 1538)\n",
      "Val embedding features shape: (19, 1538)\n",
      "X_train_stat shape: (152, 42)\n",
      "X_val_stat shape: (19, 42)\n",
      "Combined train features shape: (152, 1580)\n",
      "Combined val features shape: (19, 1580)\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy with combined features: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Thay thế cell hiện tại bằng code này:\n",
    "\n",
    "# ===== Chuẩn bị data đúng cách =====\n",
    "# Đảm bảo dùng cùng một DataFrame\n",
    "print(\"Original shapes:\")\n",
    "print(f\"train_stat_df: {train_stat_df.shape}\")\n",
    "print(f\"val_stat_df: {val_stat_df.shape}\")\n",
    "\n",
    "# Extract embedding features từ chính các DataFrame đã được chuẩn bị\n",
    "print(\"\\nExtracting embedding features...\")\n",
    "embedding_extractor = UniversalEmbeddingExtractor(model_name='intfloat/multilingual-e5-small')\n",
    "\n",
    "# Extract cho train data\n",
    "train_embedding_features = extract_embedding_features(train_stat_df, embedding_extractor)\n",
    "\n",
    "# Extract cho validation data  \n",
    "val_embedding_features = extract_embedding_features(val_stat_df, embedding_extractor)\n",
    "\n",
    "print(f\"Train embedding features shape: {train_embedding_features.shape}\")\n",
    "print(f\"Val embedding features shape: {val_embedding_features.shape}\")\n",
    "\n",
    "# ===== Chuẩn bị X, y từ cùng DataFrame =====\n",
    "X_train_stat = train_stat_df.drop(columns=[\"label\", \"file_1\", \"file_2\"])\n",
    "y_train = train_stat_df[\"label\"] - 1  # Convert to 0,1\n",
    "\n",
    "X_val_stat = val_stat_df.drop(columns=[\"label\", \"file_1\", \"file_2\"])  \n",
    "y_val = val_stat_df[\"label\"]\n",
    "\n",
    "print(f\"X_train_stat shape: {X_train_stat.shape}\")\n",
    "print(f\"X_val_stat shape: {X_val_stat.shape}\")\n",
    "\n",
    "# ===== Scale statistical features =====\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_stat)\n",
    "X_val_scaled = scaler.transform(X_val_stat)\n",
    "\n",
    "# ===== Kết hợp statistical + embedding features =====\n",
    "X_train_combined = np.concatenate([X_train_scaled, train_embedding_features], axis=1)\n",
    "X_val_combined = np.concatenate([X_val_scaled, val_embedding_features], axis=1)\n",
    "\n",
    "print(f\"Combined train features shape: {X_train_combined.shape}\")\n",
    "print(f\"Combined val features shape: {X_val_combined.shape}\")\n",
    "\n",
    "# ===== Train model =====\n",
    "model = LGBMClassifier(random_state=42, verbose=0)\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val_combined) + 1\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy with combined features: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4554cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
