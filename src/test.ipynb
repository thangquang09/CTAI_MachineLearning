{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c000d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thangquang09/CODE/CTAI_MachineLearning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước từ vựng: 9083\n",
      "Index của '<pad>': 0\n",
      "Index của một từ ngẫu nhiên 'hello': 2\n",
      "Index của một từ không có trong từ điển: 2\n"
     ]
    }
   ],
   "source": [
    "from build_dataset_dataloader import get_dataset\n",
    "\n",
    "train_dataset, val_dataset, vocabulary = get_dataset(case=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b1ea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9083"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0e2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3264f2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1069,   13,   26,  ...,    0,    0,    0],\n",
       "         [2220,  227,    4,  ..., 1376, 1781,  722]]),\n",
       " tensor([[ 261,   74,   32,  ...,    0,    0,    0],\n",
       "         [2220,  227,    4,  ...,    0,    0,    0]]),\n",
       " tensor([1., 1.])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d26b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from LSTM import SiameseLSTM\n",
    "\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1 # Output 1 giá trị logit cho binary classification\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "SEQ_LENGTH = 600\n",
    "\n",
    "model = SiameseLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acdfb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac4afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99de564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0093, Accuracy: 0.0068\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for seq1, seq2, labels in train_dataloader:\n",
    "        seq1, seq2, labels = seq1.to(device), seq2.to(device), labels.to(device)\n",
    "\n",
    "        # 1. Xóa gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. Forward pass\n",
    "        outputs = model(seq1, seq2)\n",
    "\n",
    "        # 3. Tính loss\n",
    "        # outputs có shape [batch_size, 1], cần squeeze để thành [batch_size]\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "\n",
    "        # 4. Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Cập nhật trọng số\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += outputs.argmax(dim=1).eq(labels).sum().item()\n",
    "        break\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {total_correct / len(train_dataset):.4f}')\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
