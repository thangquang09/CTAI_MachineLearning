{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3261ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from thangquang.bert_logistic import read_texts_from_dir\n",
    "import os\n",
    "\n",
    "def read_texts_from_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Reads the texts from a given directory and saves them in the pd.DataFrame with columns ['id', 'file_1', 'file_2'].\n",
    "\n",
    "    Params:\n",
    "      dir_path (str): path to the directory with data\n",
    "    \"\"\"\n",
    "    # Count number of directories in the provided path\n",
    "    dir_count = sum(\n",
    "        os.path.isdir(os.path.join(root, d))\n",
    "        for root, dirs, _ in os.walk(dir_path)\n",
    "        for d in dirs\n",
    "    )\n",
    "    data = [0 for _ in range(dir_count)]\n",
    "    print(f\"Number of directories: {dir_count}\")\n",
    "\n",
    "    # For each directory, read both file_1.txt and file_2.txt and save results to the list\n",
    "    i = 0\n",
    "    for folder_name in sorted(os.listdir(dir_path)):\n",
    "        folder_path = os.path.join(dir_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            try:\n",
    "                with open(\n",
    "                    os.path.join(folder_path, \"file_1.txt\"), \"r\", encoding=\"utf-8\"\n",
    "                ) as f1:\n",
    "                    text1 = f1.read().strip()\n",
    "                with open(\n",
    "                    os.path.join(folder_path, \"file_2.txt\"), \"r\", encoding=\"utf-8\"\n",
    "                ) as f2:\n",
    "                    text2 = f2.read().strip()\n",
    "                index = int(folder_name[-4:])\n",
    "                data[i] = (index, text1, text2)\n",
    "                i += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading directory {folder_name}: {e}\")\n",
    "\n",
    "    # Change list with results into pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"id\", \"file_1\", \"file_2\"]).set_index(\"id\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e846f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_86 = pd.read_csv(\"/home/thangquang09/CODE/CTAI_MachineLearning/notebooks/submission_e5_catboost_improved.csv\")\n",
    "df_89 = pd.read_csv(\"/home/thangquang09/CODE/CTAI_MachineLearning/notebooks/submission_api_call_full_openai.csv\")\n",
    "df_91 = pd.read_csv(\"/home/thangquang09/CODE/CTAI_MachineLearning/notebooks/submission_api_call_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9e5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_86.rename(columns={'real_text_id': 'pred_86'}, inplace=True)\n",
    "df_89.rename(columns={'real_text_id': 'pred_89'}, inplace=True)\n",
    "df_91.rename(columns={'real_text_id': 'pred_91'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a8be51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  pred_86  pred_89  pred_91\n",
      "0   0        2        2        2\n",
      "1   1        2        2        2\n",
      "2   2        1        1        1\n",
      "3   3        1        1        1\n",
      "4   4        2        2        2\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_86, df_89, on='id')\n",
    "df_merged = pd.merge(df_merged, df_91, on='id')\n",
    "\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eaa1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = df_merged['pred_86'].values\n",
    "y_pred2 = df_merged['pred_89'].values\n",
    "y_pred3 = df_merged['pred_91'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b7527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Giả sử bạn đã có dự đoán từ 3 mô hình dạng numpy arrays\n",
    "# y_pred1, y_pred2, y_pred3 là mảng dự đoán của base models\n",
    "# y_true là nhãn đúng\n",
    "\n",
    "# Weighted voting – gán trọng số theo chính xác\n",
    "weights = [86, 89, 91]  # Xem như tỉ lệ phần trăm thực tế\n",
    "y_preds = np.array([y_pred1, y_pred2, y_pred3])\n",
    "\n",
    "# Tính voting score cho từng dòng\n",
    "n_samples = y_pred1.shape[0]\n",
    "weighted_vote = np.zeros((n_samples,))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    votes = {}\n",
    "    for idx, pred in enumerate(y_preds[:, i]):\n",
    "        votes[pred] = votes.get(pred, 0) + weights[idx]\n",
    "    # Lấy nhãn có tổng weight cao nhất\n",
    "    weighted_vote[i] = max(votes, key=votes.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3821a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['real_text_id'] = weighted_vote.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fbb378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[['id', 'real_text_id']].to_csv(\"simple_voting_868991.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da977d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu trong tập test: 1068\n",
      "Tìm thấy 857 mẫu có sự đồng thuận cao.\n",
      "Có 211 mẫu được gán label 3.\n",
      "   id  ground_truth_guess\n",
      "0   0                   2\n",
      "1   1                   2\n",
      "2   2                   1\n",
      "3   3                   1\n",
      "4   4                   2\n"
     ]
    }
   ],
   "source": [
    "condition = (df_merged['pred_86'] == df_merged['pred_89']) & \\\n",
    "            (df_merged['pred_89'] == df_merged['pred_91'])\n",
    "\n",
    "# Tạo consensus_df từ toàn bộ df_merged\n",
    "consensus_df = df_merged.copy()\n",
    "\n",
    "# Với những hàng thỏa mãn điều kiện, lấy giá trị từ pred_91\n",
    "# Với những hàng không thỏa mãn, gán label là 3\n",
    "consensus_df['ground_truth_guess'] = np.where(condition, consensus_df['pred_91'], 3)\n",
    "\n",
    "print(f\"Tổng số mẫu trong tập test: {len(df_merged)}\")\n",
    "print(f\"Tìm thấy {condition.sum()} mẫu có sự đồng thuận cao.\")\n",
    "print(f\"Có {(~condition).sum()} mẫu được gán label 3.\")\n",
    "\n",
    "# Đây là một phần của ground truth mà bạn có thể tin tưởng\n",
    "print(consensus_df[['id', 'ground_truth_guess']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ebb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_df[['id', 'ground_truth_guess']].rename({\"ground_truth_guess\": \"real_text_id\"}).to_csv(\"X_test_ground_truth_with3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd5c6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred_86</th>\n",
       "      <th>pred_89</th>\n",
       "      <th>pred_91</th>\n",
       "      <th>ground_truth_guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1064</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  pred_86  pred_89  pred_91  ground_truth_guess\n",
       "0        0        2        2        2                   2\n",
       "1        1        2        2        2                   2\n",
       "2        2        1        1        1                   1\n",
       "3        3        1        1        1                   1\n",
       "4        4        2        2        2                   2\n",
       "...    ...      ...      ...      ...                 ...\n",
       "1063  1063        1        1        1                   1\n",
       "1064  1064        1        1        1                   1\n",
       "1065  1065        1        1        1                   1\n",
       "1066  1066        2        2        2                   2\n",
       "1067  1067        1        1        1                   1\n",
       "\n",
       "[1068 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cb20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 1068\n"
     ]
    }
   ],
   "source": [
    "df_test = read_texts_from_dir(\"/home/thangquang09/CODE/CTAI_MachineLearning/data/fake-or-real-the-impostor-hunt/data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e2e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy ra các index mà df_test trùng với consensus_df\n",
    "new_df = pd.merge(consensus_df[['id', 'ground_truth_guess']], df_test, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09a13d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"X_test_ground_truth.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctai-machinelearning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
